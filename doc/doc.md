How to work with this repo:

1. Clone git repo

2. Download data and put in the correct folders (TODO)

3. First look at doc folder
- Run create_preprocessed data once in the beginning
- One main IPython notebook per farm containg the high
level call of functions and the results

4. Short summary below, for detailed documentation see src folder

5. Exp folder contains experiments and data exploration in 
  

Summary:
- Task: There are three wind farms. Predict the power generated by one turbine per wind farm for the next step (=10min), next hour and next day
- Givens: 3 datasets 
UK: Kelmarsh (,)
Brazil: Berbide (uebb) (,)
Brazil: ... (ueps) (,)
Brazilian datasets: Lots of useful feature information in the xarray data strucutre that is lost once transfered to pandas
- Approach: More or less same approach taken for all three datasets.
For each dataset: 
  1. Parse data to csv and ignore all data but the turbine of interest (see data_loader.py)
  2. Make time-series data a supervised problem and generate smart features (see preprocessing.py)
  3. Train xgboost on scaled data for each farm and each prediction horizon (i.e. 3 farms * 3 predictions = 9 models) (see model.py)
  4. Visualize results (see visualizations.py)

Sidenotes:
Dimensionality reduction: Manually drop columns if too many NaNs and collaps height and range dimension of the brazilian datasets to binary
Model selection and HPO: Manually chose xgboost due to good results, with hand-tuned hyperparameters
No global model or transfer learning approach taken

Results: Beaten the benchmark in most cases examplatory image 









